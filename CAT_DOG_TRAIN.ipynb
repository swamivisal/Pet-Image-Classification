{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAT_DOG_TRAIN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swamivisal/Pet-Image-Classification/blob/main/CAT_DOG_TRAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOn45gCu_adw"
      },
      "source": [
        "##**Importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR7S6cCf-Fk4"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense,Activation,Flatten,Conv2D,MaxPool2D,Dropout\n",
        "from random import shuffle\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V9pHZHAAOCg"
      },
      "source": [
        "##**Preprocessing the training and validation data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVcxDmQV-IqC",
        "outputId": "0ce71bbb-561a-43ad-a178-924fd17262bf"
      },
      "source": [
        "\n",
        "#def augment(img):\n",
        "#M=cv2.getRotationMatrix2D((25,25),np.random.randint(-10,11),1)\n",
        "#img=cv2.warpAffine(img,M,(50,50))\n",
        "#return img\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Computer Vision/TRAIN.npy\"\n",
        "\n",
        "dataset = np.load(path,allow_pickle=True)\n",
        "print(dataset.shape)\n",
        "shuffle(dataset)\n",
        "inputs= [] \n",
        "targets = []\n",
        "\n",
        "for x,y in dataset[:20000]:\n",
        "  inputs.append(x)\n",
        "  targets.append(y)\n",
        "\n",
        "inputs=np.array(inputs)\n",
        "targets=np.array(targets)\n",
        "print(inputs.shape)\n",
        "print(targets.shape)\n",
        "normalised_inputs=inputs/255.0  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24946, 2)\n",
            "(20000, 50, 50, 3)\n",
            "(20000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAorrjgcBBRk"
      },
      "source": [
        "##**Creating the Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI_7q-Z7Ap5v"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding=\"same\",input_shape=normalised_inputs.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(64,(3,3),padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(128,(3,3),padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(256,(3,3),padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr4wL0peApAl"
      },
      "source": [
        "##**Compiling the CNN and training the model on training data and saving the best model with the less validation loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWezUazJ6TUQ",
        "outputId": "c10de4c1-e281-4041-bf10-d844b2fb32e5"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\"])\n",
        "filepath=\"/content/drive/MyDrive/Computer Vision/Model/best.hdf5\"\n",
        "checkpoint=ModelCheckpoint(filepath,monitor='val_loss',verbose=1,save_best_only=True,mode='min')\n",
        "model.fit(normalised_inputs,targets,validation_split=0.05,batch_size=64,epochs=20,callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "297/297 [==============================] - 7s 22ms/step - loss: 0.6424 - accuracy: 0.6185 - val_loss: 0.6135 - val_accuracy: 0.6860\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.61346, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 2/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.5171 - accuracy: 0.7453 - val_loss: 0.5185 - val_accuracy: 0.7690\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.61346 to 0.51849, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 3/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.4231 - accuracy: 0.8068 - val_loss: 0.4750 - val_accuracy: 0.7920\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.51849 to 0.47500, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 4/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.3541 - accuracy: 0.8455 - val_loss: 0.3997 - val_accuracy: 0.8400\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.47500 to 0.39973, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 5/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.2980 - accuracy: 0.8759 - val_loss: 0.3863 - val_accuracy: 0.8250\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.39973 to 0.38627, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 6/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.2460 - accuracy: 0.9004 - val_loss: 0.3543 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.38627 to 0.35431, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 7/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.2148 - accuracy: 0.9148 - val_loss: 0.3138 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.35431 to 0.31375, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 8/20\n",
            "297/297 [==============================] - 6s 21ms/step - loss: 0.1775 - accuracy: 0.9329 - val_loss: 0.3057 - val_accuracy: 0.8770\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.31375 to 0.30567, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 9/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.1618 - accuracy: 0.9367 - val_loss: 0.3035 - val_accuracy: 0.8720\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.30567 to 0.30348, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 10/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.1424 - accuracy: 0.9473 - val_loss: 0.3403 - val_accuracy: 0.8570\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.30348\n",
            "Epoch 11/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.1234 - accuracy: 0.9524 - val_loss: 0.2775 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.30348 to 0.27749, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 12/20\n",
            "297/297 [==============================] - 6s 21ms/step - loss: 0.1147 - accuracy: 0.9563 - val_loss: 0.2690 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.27749 to 0.26902, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 13/20\n",
            "297/297 [==============================] - 6s 21ms/step - loss: 0.1040 - accuracy: 0.9611 - val_loss: 0.2585 - val_accuracy: 0.9080\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.26902 to 0.25854, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 14/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.0977 - accuracy: 0.9645 - val_loss: 0.2524 - val_accuracy: 0.9110\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.25854 to 0.25236, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 15/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.0877 - accuracy: 0.9688 - val_loss: 0.2695 - val_accuracy: 0.9030\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.25236\n",
            "Epoch 16/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.0865 - accuracy: 0.9676 - val_loss: 0.2495 - val_accuracy: 0.9090\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.25236 to 0.24951, saving model to /content/drive/MyDrive/Computer Vision/Model/best.hdf5\n",
            "Epoch 17/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.0760 - accuracy: 0.9715 - val_loss: 0.2629 - val_accuracy: 0.9030\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.24951\n",
            "Epoch 18/20\n",
            "297/297 [==============================] - 6s 21ms/step - loss: 0.0728 - accuracy: 0.9723 - val_loss: 0.2625 - val_accuracy: 0.9010\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.24951\n",
            "Epoch 19/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.0692 - accuracy: 0.9757 - val_loss: 0.2677 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.24951\n",
            "Epoch 20/20\n",
            "297/297 [==============================] - 6s 22ms/step - loss: 0.0640 - accuracy: 0.9759 - val_loss: 0.2689 - val_accuracy: 0.9080\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.24951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2725ba8b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}